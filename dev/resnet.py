# -*- coding: utf-8 -*-
"""Focal Loos

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FY6n4krIQwEaRCfKmFrN4sHi7EdKck1D

# No correr ya esta
"""

!pip install tensorflow

!git clone https://github.com/maximocostaroman/Trabajo-Practico-Integrador-Redes-Neuronales-Profundas.git



!unzip /content/Trabajo-Practico-Integrador-Redes-Neuronales-Profundas/archive.zip

import os
import csv
import shutil
import random

# Carpetas de entrada
original_dirs = ['train', 'test']  # carpetas originales

# Carpetas de salida
base_output_dir = 'images'
train_output_dir = os.path.join(base_output_dir, 'train')
test_output_dir = os.path.join(base_output_dir, 'test')

# Crear carpetas de salida
os.makedirs(train_output_dir, exist_ok=True)
os.makedirs(test_output_dir, exist_ok=True)

# CSV de salida
csv_output = 'archive_labels.csv'

# Recolectar imágenes desde carpetas originales
all_data = []

for split in original_dirs:
    for label in os.listdir(split):
        label_path = os.path.join(split, label)
        if not os.path.isdir(label_path):
            continue
        for i, img_name in enumerate(os.listdir(label_path)):
            src_path = os.path.join(label_path, img_name)
            # Crear nombre único (ignora extensión original y usa .png)
            new_filename = f"{split}_{label}_{i:05d}.png"
            all_data.append((src_path, new_filename, label))  # (ruta_origen, nombre_nuevo, etiqueta)

# Mezclar aleatoriamente
random.shuffle(all_data)

# Dividir en train y test (80/20 por defecto)
split_ratio = 0.8
split_index = int(len(all_data) * split_ratio)
train_data = all_data[:split_index]
test_data = all_data[split_index:]

# Preparar CSV
with open(csv_output, mode='w', newline='') as csvfile:
    writer = csv.writer(csvfile)
    writer.writerow(['filename', 'label', 'split'])

    # Guardar y copiar imágenes para TRAIN
    for src_path, new_filename, label in train_data:
        dst_path = os.path.join(train_output_dir, new_filename)
        shutil.copy(src_path, dst_path)
        writer.writerow([os.path.join('train', new_filename), label, 'train'])

    # Guardar y copiar imágenes para TEST
    for src_path, new_filename, label in test_data:
        dst_path = os.path.join(test_output_dir, new_filename)
        shutil.copy(src_path, dst_path)
        writer.writerow([os.path.join('test', new_filename), label, 'test'])

"""# **CORRER A PARTIR DE ACA!!**"""

import torch
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from torchvision.io import read_image
from torchvision import tv_tensors
from torchvision.transforms import v2
from torchvision import transforms
import torchvision.transforms.functional as TF
import torch.nn.functional as F
from PIL import Image
import json
import pandas as pd
import numpy as np
import os
from collections import Counter

class ImageDataset(Dataset):
    def __init__(self, annotations_file, img_dir,
                 mode= "train",split= "train" , transform=None):
        self.img_labels = pd.read_csv(annotations_file)
        self.img_dir = img_dir
        self.transform = transform

        self.img_labels = self.img_labels[self.img_labels['split'] == split].reset_index(drop=True)
        unique_labels = sorted(self.img_labels['label'].unique())
        self.label_map = {label: i for i, label in enumerate(unique_labels)}
        self.num_classes = len(unique_labels)
        print(f"Label mapping: {self.label_map}")


    def __len__(self):
        return len(self.img_labels)

    def __getitem__(self, idx):
        img_filename_in_csv = self.img_labels.iloc[idx]['filename']
        img_path = os.path.join(self.img_dir, img_filename_in_csv)
        image = Image.open(img_path).convert('RGB')  # Convert to RGB

        # Convert the label string to its numerical index
        label_str = self.img_labels.iloc[idx]['label']
        label = self.label_map[label_str]
        # Convert the index to a long tensor
        label = torch.tensor(label, dtype=torch.long)

        if self.transform:
            image = self.transform(image)

        return image, label

# Transformaciones
import torch
from torchvision import transforms

train_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.RandomCrop(48, padding=4),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

val_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

resize = v2.Resize(size=(48,48))

train_dataset = ImageDataset(
    annotations_file= "/content/archive_labels.csv",
    img_dir= "/content/images",
    mode='train',
    split= "train",
    transform= train_transform
)

test_dataset = ImageDataset(
    annotations_file= "/content/archive_labels.csv",
    img_dir= "/content/images",
    split= "test",
    transform= val_transform
)

from collections import Counter
import numpy as np

targets = train_dataset.img_labels['label'].apply(lambda x: train_dataset.label_map[x]).tolist()

class_counts = Counter(targets)
num_classes = len(class_counts)

print("Cantidad por clase:", class_counts)

from collections import Counter
from torch.utils.data import WeightedRandomSampler

def create_weighted_sampler(train_dataset):
    # Use the 'label' column from the img_labels DataFrame
    targets = train_dataset.img_labels['label'].apply(lambda x: train_dataset.label_map[x]).tolist()

    if isinstance(targets, list):
        targets = torch.tensor(targets)
    elif isinstance(targets, torch.Tensor):
        targets = targets.cpu()

    label_counts = Counter(targets.numpy())
    happy_count = label_counts[3]

    class_weights = {
        label: 1.0 if label == 3 else happy_count / count
        for label, count in label_counts.items()
    }

    sample_weights = torch.DoubleTensor([class_weights[int(label)] for label in targets])
    sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)
    return sampler

sampler = create_weighted_sampler(train_dataset)

#Generamos los dataloaders
from torch.utils.data import DataLoader

train_loader = DataLoader(
    train_dataset,
    batch_size=64,
    num_workers=2,
    sampler=sampler
)

# DataLoader para el conjunto de prueba
test_loader = DataLoader(
    test_dataset,
    batch_size=64,
    shuffle=False,
    num_workers=2
)

import torch.nn.functional as F
import torch.nn as nn

class FocalLoss(nn.Module):
    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):
        super(FocalLoss, self).__init__()
        self.alpha = alpha  # pesos por clase
        self.gamma = gamma
        self.reduction = reduction

    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')
        pt = torch.exp(-ce_loss)
        loss = ((1 - pt) ** self.gamma) * ce_loss

        if self.reduction == 'mean':
            return loss.mean()
        elif self.reduction == 'sum':
            return loss.sum()
        else:
            return loss

from torchvision.models import resnet18, ResNet18_Weights
import torch.nn as nn

def create_rgb_resnet18(num_classes=7, dropout_p=0.6):
    model = resnet18(weights=ResNet18_Weights.DEFAULT)

    # Reemplazar solo la capa final para clasificación
    model.fc = nn.Sequential(
        nn.Dropout(p=dropout_p),
        nn.Linear(512, num_classes)
    )

    return model

from collections import Counter
import matplotlib.pyplot as plt

def train_model(model, train_loader, val_loader, optimizer, num_epochs=10, device='cuda'):
    model = model.to(device)
    train_losses, val_losses = [], []
    train_accuracies, val_accuracies = [], []

    # Obtener pesos por clase
    all_labels = []
    for _, labels in train_loader:
        all_labels.extend(labels.numpy())
    label_counts = Counter(all_labels)
    num_classes = len(label_counts)
    total_samples = sum(label_counts.values())
    class_weights = [total_samples / (num_classes * label_counts[i]) for i in range(num_classes)]
    weight_tensor = torch.FloatTensor(class_weights).to(device)

    # Usar Focal Loss en vez de CrossEntropy
    criterion = FocalLoss(alpha=weight_tensor, gamma=2.0)

    best_val_acc = 0.0
    best_model_state = None

    for epoch in range(num_epochs):
        model.train()
        running_loss, correct, total = 0.0, 0, 0

        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        epoch_train_loss = running_loss / len(train_loader.dataset)
        epoch_train_acc = correct / total
        train_losses.append(epoch_train_loss)
        train_accuracies.append(epoch_train_acc)

        # Validación
        model.eval()
        val_loss, correct, total = 0.0, 0, 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item() * images.size(0)
                _, predicted = torch.max(outputs, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        epoch_val_loss = val_loss / len(val_loader.dataset)
        val_accuracy = correct / total
        val_losses.append(epoch_val_loss)
        val_accuracies.append(val_accuracy)

        # Guardar mejor modelo
        if val_accuracy > best_val_acc:
            best_val_acc = val_accuracy
            best_model_state = model.state_dict()

        print(f"Epoch {epoch+1}/{num_epochs} | Train Loss: {epoch_train_loss:.4f}, Acc: {epoch_train_acc:.4f} | "
              f"Val Loss: {epoch_val_loss:.4f}, Acc: {val_accuracy:.4f}")

    # Graficar
    plt.figure(figsize=(12,5))
    plt.subplot(1,2,1)
    plt.plot(train_losses, label="Train Loss")
    plt.plot(val_losses, label="Validation Loss")
    plt.title("Loss")
    plt.xlabel("Epoch"); plt.ylabel("Loss"); plt.legend()

    plt.subplot(1,2,2)
    plt.plot(train_accuracies, label="Train Acc")
    plt.plot(val_accuracies, label="Val Acc")
    plt.title("Accuracy")
    plt.xlabel("Epoch"); plt.ylabel("Accuracy"); plt.legend()

    plt.tight_layout()
    plt.show()

    # Guardar mejor modelo
    if best_model_state:
        torch.save(best_model_state, 'mejor_modelo_focal_loss.pth')
        print(f"✅ Mejor modelo guardado con val_accuracy = {best_val_acc:.4f}")

    return train_accuracies, val_accuracies

model = create_rgb_resnet18()
sampler = create_weighted_sampler(train_dataset)

train_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler)
val_loader = DataLoader(test_dataset, batch_size=64, shuffle=False) # Corrected val_loader to use test_dataset

optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

train_model(model, train_loader, val_loader, optimizer, num_epochs=20, device='cuda')

import matplotlib.pyplot as plt

labels_in_batch = []
for images, labels in train_loader:
    labels_in_batch.extend(labels.tolist())
    if len(labels_in_batch) > 1000:
        break

# Ver histograma
plt.hist(labels_in_batch, bins=range(num_classes+1), align='left', rwidth=0.8)
plt.title("Distribución de clases en batches balanceados")
plt.xlabel("Clase")
plt.ylabel("Frecuencia")
plt.show()

from sklearn.metrics import classification_report, confusion_matrix
import torch
import matplotlib.pyplot as plt
import seaborn as sns

def evaluate_model(model, val_loader, device='cuda', show_report=True):
    model.eval()
    model.to(device)

    true_labels = []
    pred_labels = []

    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)

            true_labels.extend(labels.cpu().numpy())
            pred_labels.extend(preds.cpu().numpy())

    if show_report:
        target_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']
        print("📊 Classification Report:\n")
        print(classification_report(true_labels, pred_labels, target_names=target_names, digits=4))

        # Confusion matrix
        cm = confusion_matrix(true_labels, pred_labels)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=target_names, yticklabels=target_names)
        plt.title("Matriz de Confusión")
        plt.xlabel("Predicted label")
        plt.ylabel("True label")
        plt.show()

    return true_labels, pred_labels

# Suponiendo que ya tenés model y val_loader definidos
true_labels, pred_labels = evaluate_model(model, val_loader, device='cuda')